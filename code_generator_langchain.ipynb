{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44ce0f9-cf66-4a7a-8f6b-454a56a42187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\niran\\anaconda3\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\niran\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\niran\\anaconda3\\lib\\site-packages (0.1.17)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.20-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain in c:\\users\\niran\\anaconda3\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: langgraph in c:\\users\\niran\\anaconda3\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\niran\\anaconda3\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain-openai) (1.36.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchainhub) (24.1)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (1.10.12)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (1.18.1)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 0.0/67.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.3/67.3 kB 3.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (1.64.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (3.10.6)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\niran\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (3.1.3)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.22->langchain_community) (1.33)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\niran\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\niran\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\niran\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\niran\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.8.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (70.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.3.5)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\niran\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain_community) (2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\niran\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n",
      "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "   ---------------------------------------- 0.0/584.3 kB ? eta -:--:--\n",
      "   --------------------------- ----------- 409.6/584.3 kB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 584.3/584.3 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.9/151.9 kB ? eta 0:00:00\n",
      "Downloading bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
      "   ---------------------------------------- 0.0/92.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 92.2/92.2 kB ? eta 0:00:00\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.4/1.7 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading mmh3-4.1.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.0/138.0 kB ? eta 0:00:00\n",
      "Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "   ---------------------------------------- 0.0/109.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 109.5/109.5 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.3/41.3 kB ? eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB ? eta 0:00:00\n",
      "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "   ---------------------------------------- 0.0/195.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 195.5/195.5 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 220.0/220.0 kB ? eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.7/151.7 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB ? eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl (281 kB)\n",
      "   ---------------------------------------- 0.0/282.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 282.0/282.0 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 307.7/307.7 kB 19.8 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53835 sha256=d254b2050def226608548e27812e1ddfb9131af8ba68f117378fab78f9d64499\n",
      "  Stored in directory: c:\\users\\niran\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, websockets, types-requests, tenacity, shellingham, rsa, python-multipart, pyproject_hooks, opentelemetry-util-http, opentelemetry-proto, oauthlib, importlib-resources, httptools, googleapis-common-protos, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, google-auth, email_validator, build, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 chroma-hnswlib-0.7.6 chromadb-0.5.5 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 google-auth-2.32.0 googleapis-common-protos-1.63.2 httptools-0.6.1 importlib-resources-6.4.0 kubernetes-30.1.0 langchainhub-0.1.20 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-multipart-0.0.9 requests-oauthlib-2.0.0 rsa-4.9 shellingham-1.5.4 starlette-0.37.2 tenacity-8.5.0 typer-0.12.3 types-requests-2.32.0.20240712 uvicorn-0.30.3 watchfiles-0.22.0 websockets-12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e835d-1c25-40f6-a059-2692db3b806f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0686f365-b8d3-47de-bf1d-8581cc149706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "# Grader prompt\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a coding assistant with expertise in Python programming. Answer the user question \\n\n",
    "    in code you provide can be executed with all required imports and variables defined. \\n\n",
    "    Structure your answer with a description of the code solution. \\n\n",
    "    Then list the imports. And finally list the functioning code block. Here is the user question:\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Data model\n",
    "class code(BaseModel):\n",
    "    \"\"\"Code output\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "    description = \"Schema for code solutions to questions about Python.\"\n",
    "\n",
    "assert os.path.exists(\"openai_key.txt\")\n",
    "\n",
    "with open(\"openai_key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", api_key=api_key)\n",
    "code_gen_chain = code_gen_prompt | llm.with_structured_output(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dfe3f0c5-f124-45ad-9c51-9d1c4dd6d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain to get the solution\n",
    "solution = code_gen_chain.invoke({\"messages\": [(\"user\", \"Build a RAG chain?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d4ffdc07-09c9-4c53-a93c-c08b65f40e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a Retrieval-Augmented Generation (RAG) chain, we will use a combination of a retriever and a generator. The retriever will fetch relevant documents based on a query, and the generator will produce a response based on the retrieved documents. In this example, we will use a simple in-memory document store and a basic text generation model.\n",
      "from transformers import pipeline\n",
      "from typing import List, Tuple\n",
      "\n",
      "# Sample documents for retrieval\n",
      "documents = [\n",
      "    \"The sky is blue and beautiful.\",\n",
      "    \"The sun is shining bright today.\",\n",
      "    \"The quick brown fox jumps over the lazy dog.\",\n",
      "    \"Python is a great programming language for data science.\"\n",
      "]\n",
      "def retrieve_documents(query: str, documents: List[str], top_k: int = 2) -> List[str]:\n",
      "    # Simple keyword-based retrieval\n",
      "    return [doc for doc in documents if query.lower() in doc.lower()][:top_k]\n",
      "\n",
      "\n",
      "def generate_response(retrieved_docs: List[str]) -> str:\n",
      "    generator = pipeline('text-generation', model='gpt2')\n",
      "    combined_text = '\\n'.join(retrieved_docs)\n",
      "    response = generator(combined_text, max_length=50, num_return_sequences=1)\n",
      "    return response[0]['generated_text']\n",
      "\n",
      "\n",
      "def rag_chain(query: str) -> str:\n",
      "    retrieved_docs = retrieve_documents(query, documents)\n",
      "    response = generate_response(retrieved_docs)\n",
      "    return response\n",
      "\n",
      "# Example usage\n",
      "query = \"sky\"\n",
      "result = rag_chain(query)\n",
      "print(result)\n"
     ]
    }
   ],
   "source": [
    "# Access the structured output\n",
    "print(solution.prefix)   # Description of the problem and approach\n",
    "print(solution.imports)  # Required import statements\n",
    "print(solution.code)     # The actual code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff87d7-e0c7-4d9e-8d07-3ab754322a7a",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7078ea9c-b407-47ea-8c47-344e84655852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285f3ad-80a5-4aff-8919-6b2e20caf34a",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a115087a-6445-4248-8438-8d17b29b3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "### Parameter\n",
    "\n",
    "# Max tries\n",
    "max_iterations = 3\n",
    "# Reflect\n",
    "# flag = 'reflect'\n",
    "flag = \"do not reflect\"\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = code_gen_chain.invoke(\n",
    "        {\"messages\": [(\"user\", question)]}\n",
    "    )\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Get solution components\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Check execution\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO CODE TEST FAILURES---\")\n",
    "    return {\n",
    "        \"generation\": code_solution,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "\n",
    "    # Prompt reflection\n",
    "\n",
    "    # Add reflection\n",
    "    reflections = code_gen_chain.invoke(\n",
    "        {\"messages\": [(\"user\", question)]}\n",
    "    )\n",
    "    messages += [(\"assistant\", f\"Here are reflections on the error: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        if flag == \"reflect\":\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c8694e4-a5dc-4615-a647-d176edc78265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code\", code_check)  # check code\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reflect\", \"generate\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f995c24-0f1f-4855-ab71-f5316ca4e888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "---CODE IMPORT CHECK: FAILED---\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "Based on the information retrieved:\n",
      "Document 3: Guide to building web applications.\n",
      "Document 4: Introduction to data science.\n",
      "---NO CODE TEST FAILURES---\n",
      "---DECISION: FINISH---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': 'no',\n",
       " 'messages': [('user', 'How do I build a RAG chain?'),\n",
       "  ('assistant',\n",
       "   'To build a Retrieval-Augmented Generation (RAG) chain, we need to combine a retriever and a generator. The retriever fetches relevant documents based on a query, and the generator produces a response using the retrieved documents. In this example, we will use a simple in-memory document store and a transformer-based model for generation. \\n Imports: from transformers import pipeline\\nfrom typing import List, Tuple\\n\\n# Sample documents for retrieval\\ndocuments = [\\n    \"The sky is blue.\",\\n    \"The sun is bright.\",\\n    \"The grass is green.\",\\n    \"The ocean is vast.\"\\n] \\n Code: def retrieve_documents(query: str, documents: List[str], top_k: int = 2) -> List[str]:\\n    # Simple keyword-based retrieval\\n    return [doc for doc in documents if query.lower() in doc.lower()][:top_k]\\n\\n\\ndef generate_response(query: str, retrieved_docs: List[str]) -> str:\\n    # Initialize a text generation pipeline\\n    generator = pipeline(\\'text-generation\\', model=\\'gpt2\\')\\n    context = \\'\\\\n\\'.join(retrieved_docs) + \\'\\\\n\\' + query\\n    response = generator(context, max_length=50, num_return_sequences=1)\\n    return response[0][\\'generated_text\\']\\n\\n\\ndef rag_chain(query: str) -> str:\\n    retrieved_docs = retrieve_documents(query, documents)\\n    response = generate_response(query, retrieved_docs)\\n    return response\\n\\n# Example usage\\nquery = \"What color is the sky?\"\\nresult = rag_chain(query)\\nprint(result)'),\n",
       "  ('user',\n",
       "   \"Your solution failed the import test: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\\ncannot import name 'get_model_proto' from 'tensorflow.python.data.experimental.ops.iterator_ops' (C:\\\\Users\\\\niran\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\data\\\\experimental\\\\ops\\\\iterator_ops.py)\"),\n",
       "  ('user',\n",
       "   'Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:'),\n",
       "  ('assistant',\n",
       "   'To build a Retrieval-Augmented Generation (RAG) chain, we need to combine a retrieval mechanism with a generative model. The retrieval component fetches relevant documents or information based on a query, and the generative model uses this information to produce a coherent response. In this example, we will use a simple approach with a mock retrieval function and a generative function that simulates the response generation. \\n Imports: from typing import List, Tuple\\nimport random \\n Code: def mock_retrieval(query: str) -> List[str]:\\n    # Simulate a retrieval process by returning random documents\\n    documents = [\\n        \\'Document 1: Information about Python programming.\\',\\n        \\'Document 2: Overview of machine learning techniques.\\',\\n        \\'Document 3: Guide to building web applications.\\',\\n        \\'Document 4: Introduction to data science.\\',\\n    ]\\n    return random.sample(documents, k=2)  # Return 2 random documents\\n\\ndef generate_response(retrieved_docs: List[str]) -> str:\\n    # Simulate response generation based on retrieved documents\\n    response = \"Based on the information retrieved:\\\\n\"\\n    response += \\'\\\\n\\'.join(retrieved_docs)\\n    return response\\n\\n# Example usage\\nquery = \\'Tell me about programming.\\'\\nretrieved_docs = mock_retrieval(query)\\nresponse = generate_response(retrieved_docs)\\nprint(response)')],\n",
       " 'generation': code(prefix='To build a Retrieval-Augmented Generation (RAG) chain, we need to combine a retrieval mechanism with a generative model. The retrieval component fetches relevant documents or information based on a query, and the generative model uses this information to produce a coherent response. In this example, we will use a simple approach with a mock retrieval function and a generative function that simulates the response generation.', imports='from typing import List, Tuple\\nimport random', code='def mock_retrieval(query: str) -> List[str]:\\n    # Simulate a retrieval process by returning random documents\\n    documents = [\\n        \\'Document 1: Information about Python programming.\\',\\n        \\'Document 2: Overview of machine learning techniques.\\',\\n        \\'Document 3: Guide to building web applications.\\',\\n        \\'Document 4: Introduction to data science.\\',\\n    ]\\n    return random.sample(documents, k=2)  # Return 2 random documents\\n\\ndef generate_response(retrieved_docs: List[str]) -> str:\\n    # Simulate response generation based on retrieved documents\\n    response = \"Based on the information retrieved:\\\\n\"\\n    response += \\'\\\\n\\'.join(retrieved_docs)\\n    return response\\n\\n# Example usage\\nquery = \\'Tell me about programming.\\'\\nretrieved_docs = mock_retrieval(query)\\nresponse = generate_response(retrieved_docs)\\nprint(response)', description='This code simulates a simple RAG chain with a mock retrieval function and a response generation function.'),\n",
       " 'iterations': 2}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I build a RAG chain?\"\n",
    "app.invoke({\"messages\": [(\"user\", question)], \"iterations\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6307078-c186-4686-a05c-66c53b9cd422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
